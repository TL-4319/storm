STORM
======
A python software for Storm Tracking On-orbit using RFS with Complementary MOS (STORM) developed by the Laboratory for Autonomy, GNC, and Estimation Research (LAGER) at the University of Alabama (UA)

## Dev environment
To facilitate development of STORM which requires concurrent development in CARBS, ```git submodules``` is used. CARBS submodule tracks the ```ggiw-dev``` [branch](https://github.com/drjdlarson/carbs/tree/ggiw-dev).

Clone the repository locally on your computer, using

```
git clone --recurse-submodules https://github.com/TL-4319/storm.git
```

For windows it is recommended to clone it within your linux subsystem directory (e.g. a sub-directory of your linux home folder) to improve performance within the container (the linux directories on Windows can be accessed through the file browser by typing ```\\wsl$``` in the address bar and clicking on your distro).

It is highly recommended to use VS Code with the dev containers extension. 

## Workflow
After a dev container is spun up, the shell is logged in as non-root user ```vscode``` so that any file created is not root-acess limited in the host machine. NOTE: vscode still has root proviledge in the containter.

The terminal by default will not have a shell environment i.e. shows up as just ```$```. Enter ```bash``` to begin a bash environment for nice features.

### Development in CARBS
After implementing new feature in CARBS submodule and ready for test withint the container, build CARBS locally. NOTE: Don't forget "./" prefixing carbs to install the correct version.

```
pip3 install -e ./carbs
```

CARBS submodule is tracked via its own git and needs to be commit and push from within ```storm/carbs```. Submodule git commit then follows accordingly.

### Developing STORM application
If a code requires import from CARBS, make sure to build the latest local CARBS package.

### Preprocessing data
LIS data from ISS can be acquired from [here](https://search.earthdata.nasa.gov/search?q=lightning&fi=LIS). Make sure to get both science and background data in netCDF format. Files are to be saved in ```storm/dataset``` directory.

#### Generate background video
Videos from background LIS images are generated by running ```make_bg_video.py```. Modify ```granule``` variable to reflect which orbit you want to pre-process. You can also change the size of the output video for visual clarity. ```dt``` change the time step of the video. Image frames are constant for interpolation in the time vector as frames are capture at different timescale compare to the ```dt```. The video is overlayed with TAI93 timestamps. Video is output as ```storm/dataset/<granule>/background.avi```.

#### Generate measurement data
Raw LIS data can be prepared into measurement tables using ```pre_process_event.py``` script by first modifying the ```granule``` variable to select the desired dataset. ```dt``` allows control over the timescale of the dataset. As LIS has framerate upto 500Hz, measurement are group into time bin with widths equal to ```dt```. The script output a video of the events along with TAI93 timestamps in ```storm/dataset/<granule>/events.avi```. The script also generates a pickle file in ```storm/dataset/<granule>/events.pik``` which contains dictionary ```meas_data``` which contains the following keys for Z number of measurements step:
- ```TAI93_time_s``` [Z x1 ] numpy array
- ```elapsed_time_s``` [Z x 1] numpy array. Essentially ```TAI93_time_s - TAI93_time_s[0]```
- ```meas_tab``` list of size [Z] where ```meas_tab[k] = np.nan``` if there are no measurement at k. If k has measurement then ```meas_tab[k] = meas``` where ```meas``` is a [n x 2] numpy array where n is the number of measurement at that time step. The first and second column contains the X and Y pixel location, respectively. 

